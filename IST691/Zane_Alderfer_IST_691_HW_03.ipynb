{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZ7cPfCty5U3"
   },
   "source": [
    "# IST 691: Deep Learning in Practice\n",
    "\n",
    "**Homework 3**\n",
    "\n",
    "Name: Zane Alderfer\n",
    "\n",
    "SUID: 503765874\n",
    "\n",
    "*Save this notebook into your Google Drive. The notebook has appropriate comments at the top of code cells to indicate whether you need to modify them or not. Answer your questions directly in the notebook. Remember to use the GPU as your runtime. Once finished, run ensure all code blocks are run, download the notebook and submit through Blackboard.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g8swbTwkCunA"
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "60F0x-u40An9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-28 15:39:10.043150: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/zanealderfer/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/Users/zanealderfer/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/Users/zanealderfer/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "import string\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# to build nearest neighbor model\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9672 sha256=6a0f45fd71f51d323dc2bf6f08da83b16e778bcd1daa6d985083684f020f3cf8\n",
      "  Stored in directory: /Users/zanealderfer/Library/Caches/pip/wheels/04/5f/3e/46cc37c5d698415694d83f607f833f83f0149e49b3af9d0f38\n",
      "Successfully built wget\n",
      "\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: wget\n",
      "Successfully installed wget-3.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p3AEhdYAMBPN"
   },
   "source": [
    "In this homework, we will perform **sarcasm detection** with [Onion](https://www.theonion.com/) vs [HuffPost](https://www.huffpost.com/) headlines, using LSTM. We will first load the data and generate the training and testing input and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "JlmQdvJtL_Si"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: wget: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!wget -nc -q https://github.com/mrech/NLP_TensorFlow/blob/master/0_Sentiment_in_Text/Sarcasm_Headlines_Dataset_v2.json?raw=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   is_sarcastic                                           headline  \\\n",
      "0             1  thirtysomething scientists unveil doomsday clo...   \n",
      "1             0  dem rep. totally nails why congress is falling...   \n",
      "2             0  eat your veggies: 9 deliciously different recipes   \n",
      "3             1  inclement weather prevents liar from getting t...   \n",
      "4             1  mother comes pretty close to using word 'strea...   \n",
      "\n",
      "                                        article_link  \n",
      "0  https://www.theonion.com/thirtysomething-scien...  \n",
      "1  https://www.huffingtonpost.com/entry/donna-edw...  \n",
      "2  https://www.huffingtonpost.com/entry/eat-your-...  \n",
      "3  https://local.theonion.com/inclement-weather-p...  \n",
      "4  https://www.theonion.com/mother-comes-pretty-c...  \n"
     ]
    }
   ],
   "source": [
    "# Path to the JSON file\n",
    "file_path = '/Users/zanealderfer/Downloads/Sarcasm_Headlines_Dataset_v2.json'\n",
    "\n",
    "# Read the JSON file into a DataFrame\n",
    "try:\n",
    "    df = pd.read_json(file_path, lines=True)  # Use lines=True if each line is a valid JSON object\n",
    "    print(df.head())  # Display the first few rows of the DataFrame\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "oefWYDEBBoQz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28619 entries, 0 to 28618\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   is_sarcastic  28619 non-null  int64 \n",
      " 1   headline      28619 non-null  object\n",
      " 2   article_link  28619 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 670.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# get information about the data frame\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "4zt5i54PMfLF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['thirtysomething scientists unveil doomsday clock of hair loss',\n",
       "        1],\n",
       "       ['dem rep. totally nails why congress is falling short on gender, racial equality',\n",
       "        0],\n",
       "       ['eat your veggies: 9 deliciously different recipes', 0],\n",
       "       ['inclement weather prevents liar from getting to work', 1],\n",
       "       [\"mother comes pretty close to using word 'streaming' correctly\",\n",
       "        1]], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a peek at the key data\n",
    "df[['headline', 'is_sarcastic']].head(5).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "TxA-gljoMt4G"
   },
   "outputs": [],
   "source": [
    "# the training input sequence will be in variable seq_padd_train and the label in train_y\n",
    "# The testing input sequence will be in variable seq_padd_test and the label in test_y\n",
    "headlines = df['headline'].values.tolist()\n",
    "sarcastic = df['is_sarcastic'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "8L2cvpK9Mt4H"
   },
   "outputs": [],
   "source": [
    "training_size = 20000\n",
    "test_size = 6709\n",
    "\n",
    "train_x = headlines[:training_size]\n",
    "test_x = headlines[training_size:]\n",
    "train_y = np.array(sarcastic[:training_size])\n",
    "test_y = np.array(sarcastic[training_size:])\n",
    "\n",
    "# sequence of words input\n",
    "max_len = 16\n",
    "\n",
    "tokenizer = Tokenizer(oov_token = '<OOV>')\n",
    "tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "index_word = {v: k for k, v in word_index.items()}\n",
    "vocab_size = len(word_index)\n",
    "sequence_train = tokenizer.texts_to_sequences(train_x)\n",
    "seq_padd_train = pad_sequences(sequence_train,\n",
    "                               padding = 'post',\n",
    "                               truncating = 'post',\n",
    "                               maxlen = max_len)\n",
    "\n",
    "\n",
    "sequence_test = tokenizer.texts_to_sequences(test_x)\n",
    "seq_padd_test = pad_sequences(sequence_test, padding = 'post',\n",
    "                              truncating = 'post',\n",
    "                              maxlen = max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9GPBdovEzBmE"
   },
   "source": [
    "### Q1 Calculating the Trainable Parameters of an LSTM\n",
    "\n",
    "Below is the summary of an LSTM neural network with embeddings and three layers. Explain in detail, after this cell, the \"why\" of the number of parameters of each of the layers displayed by `model1.summary()`. Cite any sources you used to answer this question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ch0XFkqgvgg"
   },
   "source": [
    "`model1.summary()`\n",
    "```\n",
    "Model: \"model\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "input_1 (InputLayer)         [(None, None)]            0         \n",
    "_________________________________________________________________\n",
    "embedding (Embedding)        (None, None, 100)         2000100   \n",
    "_________________________________________________________________\n",
    "lstm (LSTM)                  (None, None, 128)         117248    \n",
    "_________________________________________________________________\n",
    "lstm_1 (LSTM)                (None, None, 96)          86400     \n",
    "_________________________________________________________________\n",
    "lstm_2 (LSTM)                (None, 64)                41216     \n",
    "_________________________________________________________________\n",
    "predictions (Dense)          (None, 1)                 65        \n",
    "=================================================================\n",
    "Total params: 2,245,029\n",
    "Trainable params: 2,245,029\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejPWV0vj0J34"
   },
   "source": [
    "**Why do we have the number of parameters after each of the layers?**\n",
    "\n",
    "The InputLayer does not have any parameters. It simply defines the shape of the input data, which in this case is a sequence of variable length.\n",
    "\n",
    "The embedding layer maps input integers to dense vectors of fixed size. The number of parameters is calculated as:\n",
    "Number of parameters = Vocabulary size × Embedding dimension\n",
    "\n",
    "An LSTM layer has the following parameters:\n",
    "Parameters = 4 × (Input dimension × Units + Units^2 + Units)\n",
    "\n",
    "A dense layer has the following parameters:\n",
    "Parameters = Input dimension × Units + Units\n",
    "\n",
    "The total number of parameters is the sum of parameters from all layers:\n",
    "\n",
    "Total parameters = 2,000,100+ 117,248 + 86,400 + 41,216 + 65 = 2,245,029\n",
    " \n",
    "References:\n",
    "\n",
    "Brownlee, J. (2017). How to Configure the Number of Layers and Nodes in an LSTM Network. Machine Learning Mastery.\n",
    "Understanding LSTM Networks. (2015). Retrieved from colah's blog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3JcopEi-R6f"
   },
   "source": [
    "### Q2: LSTM for Detecting Sarcasm\n",
    "\n",
    "Modify the code below to create an embedding layer of dimension 50. The vocabulary size is in variable `vocab_size`, and remember to add one in the embedding for the \"out of vocabulary\" input. Define an LSTM with two layers, one with 64 memory size and the second with 32 memory size. Remember to use the suffix `2` for each of the variables you define (e.g., `x2`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "eJ72k-16EJA9"
   },
   "outputs": [],
   "source": [
    "# an integer input for vocab indices\n",
    "inputs2 = tf.keras.Input(shape = (None,), dtype = 'int32')\n",
    "\n",
    "embedding_dim = 50\n",
    "\n",
    "# define the layers below Embedding -> LSTM 1 -> LSTM 2\n",
    "x2 = layers.Embedding(input_dim=vocab_size + 1, output_dim=embedding_dim, name='embedding2')(inputs2)\n",
    "x2 = layers.LSTM(64, return_sequences=True, name='lstm1_2')(x2)\n",
    "x2 = layers.LSTM(32, name='lstm2_2')(x2)\n",
    "\n",
    "# we project onto a single unit output layer, and squash it with a sigmoid\n",
    "predictions2 = layers.Dense(1, activation = 'sigmoid', name = 'predictions')(x2)\n",
    "\n",
    "model2 = tf.keras.Model(inputs2, predictions2, name = 'lstm_simple')\n",
    "\n",
    "# compile the model with binary crossentropy loss and an adam optimizer\n",
    "model2.compile(loss = 'binary_crossentropy',\n",
    "               optimizer = 'adam',\n",
    "               metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "HtQCIAoOEREC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "282/282 - 18s - loss: 0.4286 - accuracy: 0.7887 - val_loss: 0.3297 - val_accuracy: 0.8555 - 18s/epoch - 62ms/step\n",
      "Epoch 2/10\n",
      "282/282 - 11s - loss: 0.1815 - accuracy: 0.9311 - val_loss: 0.3735 - val_accuracy: 0.8355 - 11s/epoch - 39ms/step\n",
      "Epoch 3/10\n",
      "282/282 - 10s - loss: 0.0838 - accuracy: 0.9727 - val_loss: 0.4960 - val_accuracy: 0.8300 - 10s/epoch - 37ms/step\n",
      "Epoch 4/10\n",
      "282/282 - 11s - loss: 0.0509 - accuracy: 0.9838 - val_loss: 0.5862 - val_accuracy: 0.8370 - 11s/epoch - 39ms/step\n",
      "Epoch 5/10\n",
      "282/282 - 22s - loss: 0.0306 - accuracy: 0.9906 - val_loss: 0.6400 - val_accuracy: 0.8310 - 22s/epoch - 78ms/step\n",
      "Epoch 6/10\n",
      "282/282 - 20s - loss: 0.0179 - accuracy: 0.9947 - val_loss: 0.8234 - val_accuracy: 0.8260 - 20s/epoch - 69ms/step\n",
      "Epoch 7/10\n",
      "282/282 - 16s - loss: 0.0140 - accuracy: 0.9957 - val_loss: 0.8475 - val_accuracy: 0.8315 - 16s/epoch - 56ms/step\n",
      "Epoch 8/10\n",
      "282/282 - 12s - loss: 0.0110 - accuracy: 0.9974 - val_loss: 0.8335 - val_accuracy: 0.8295 - 12s/epoch - 43ms/step\n",
      "Epoch 9/10\n",
      "282/282 - 11s - loss: 0.0102 - accuracy: 0.9973 - val_loss: 0.9724 - val_accuracy: 0.8240 - 11s/epoch - 40ms/step\n",
      "Epoch 10/10\n",
      "282/282 - 11s - loss: 0.0084 - accuracy: 0.9978 - val_loss: 0.9254 - val_accuracy: 0.8190 - 11s/epoch - 39ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fbd7d7a19a0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 10\n",
    "# fit the model using the train and test datasets\n",
    "model2.fit(seq_padd_train, train_y,\n",
    "           validation_split = 0.1,\n",
    "           epochs = epochs,\n",
    "           verbose = 2,\n",
    "           batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "pSQR8VMIEYur"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 5s 17ms/step - loss: 0.8624 - accuracy: 0.8286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8624102473258972, 0.8286344408988953]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# estimate the test performance\n",
    "model2.evaluate(seq_padd_test, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOvzWswaN3_g"
   },
   "source": [
    "### Q3: GloVe Word Embeddings\n",
    "\n",
    "Use the code below to download the GloVe embeddings and create the matrix `embedding_matrix` corresponding to the vocabulary above. Define a layer `embedding_layer_glove` which will be use by the LSTM below. Evaluate the performance and compare to model above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "EgIsgRm-Ok1h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "embeddings_index = {}\n",
    "f = open('/Users/zanealderfer/Downloads/glove.6B/glove.6B.100d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype = 'float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Mkd0RxToOtcB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 21242 words (4656 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = vocab_size + 2\n",
    "embedding_dim3 = 100\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim3))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        # this includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VGynV5Vla4s0"
   },
   "source": [
    "Create the embedding layer below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "qEG5zcMhPatR"
   },
   "outputs": [],
   "source": [
    "# create the embedding layer using the embedding_matrix from above\n",
    "embedding_layer_glove = layers.Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim3,\n",
    "    input_length = max_len,\n",
    "    embeddings_initializer = tf.keras.initializers.Constant(embedding_matrix),\n",
    "    trainable = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "6UHnlij6Plr4"
   },
   "outputs": [],
   "source": [
    "# an integer input for vocab indices\n",
    "inputs3 = tf.keras.Input(shape = (None,), dtype = 'int32')\n",
    "\n",
    "# next, we add a layer to map those vocab indices into a space of dimensionality\n",
    "x3 = embedding_layer_glove(inputs3)\n",
    "\n",
    "x3 = layers.LSTM(32)(x3)\n",
    "\n",
    "# we project onto a single unit output layer, and squash it with a sigmoid\n",
    "predictions3 = layers.Dense(1, activation = 'sigmoid', name = 'predictions')(x3)\n",
    "\n",
    "model3 = tf.keras.Model(inputs3, predictions3)\n",
    "\n",
    "# compile the model with binary crossentropy loss and an adam optimizer.\n",
    "model3.compile(loss = 'binary_crossentropy',\n",
    "               optimizer = 'adam',\n",
    "               metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "izs4Y_kgPsPG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "282/282 - 6s - loss: 0.5367 - accuracy: 0.7200 - val_loss: 0.4460 - val_accuracy: 0.7990 - 6s/epoch - 20ms/step\n",
      "Epoch 2/10\n",
      "282/282 - 2s - loss: 0.4082 - accuracy: 0.8181 - val_loss: 0.3969 - val_accuracy: 0.8210 - 2s/epoch - 8ms/step\n",
      "Epoch 3/10\n",
      "282/282 - 2s - loss: 0.3665 - accuracy: 0.8382 - val_loss: 0.3670 - val_accuracy: 0.8370 - 2s/epoch - 8ms/step\n",
      "Epoch 4/10\n",
      "282/282 - 3s - loss: 0.3313 - accuracy: 0.8579 - val_loss: 0.3651 - val_accuracy: 0.8405 - 3s/epoch - 9ms/step\n",
      "Epoch 5/10\n",
      "282/282 - 2s - loss: 0.3059 - accuracy: 0.8699 - val_loss: 0.3415 - val_accuracy: 0.8545 - 2s/epoch - 8ms/step\n",
      "Epoch 6/10\n",
      "282/282 - 2s - loss: 0.2906 - accuracy: 0.8770 - val_loss: 0.3443 - val_accuracy: 0.8535 - 2s/epoch - 8ms/step\n",
      "Epoch 7/10\n",
      "282/282 - 2s - loss: 0.2692 - accuracy: 0.8886 - val_loss: 0.3419 - val_accuracy: 0.8525 - 2s/epoch - 8ms/step\n",
      "Epoch 8/10\n",
      "282/282 - 2s - loss: 0.2531 - accuracy: 0.8946 - val_loss: 0.3424 - val_accuracy: 0.8590 - 2s/epoch - 9ms/step\n",
      "Epoch 9/10\n",
      "282/282 - 3s - loss: 0.2360 - accuracy: 0.9053 - val_loss: 0.3461 - val_accuracy: 0.8505 - 3s/epoch - 9ms/step\n",
      "Epoch 10/10\n",
      "282/282 - 2s - loss: 0.2254 - accuracy: 0.9095 - val_loss: 0.3553 - val_accuracy: 0.8560 - 2s/epoch - 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fbd75556e80>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model using the train and test datasets\n",
    "epochs = 10\n",
    "model3.fit(seq_padd_train, train_y,\n",
    "           validation_split = 0.1,\n",
    "           epochs = epochs,\n",
    "           verbose = 2,\n",
    "           batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "TxwFJaqyPuxm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 1s 5ms/step - loss: 0.3492 - accuracy: 0.8551\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3492344319820404, 0.8550875782966614]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(seq_padd_test, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pj7HmAtdbbzh"
   },
   "source": [
    "Is it better or worse performance compared to `model2`? Why?\n",
    "\n",
    "Model3 is worse compared to model2.  Fewer LSTM layers (as in model3) may be less prone to overfitting and faster to train but might not capture as complex patterns.  Model2 could potentially perform better on large datasets with sufficient training data because its trainable embeddings and multiple LSTM layers can learn more specific patterns and features from the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6y6P_ep9P5r3"
   },
   "source": [
    "### Q4: Word Analogies\n",
    "\n",
    "Above, we created the matrix `embedding_matrix` for the vocabulary in the sarcasm dataset. Use the code below to find the word analogy to \"`germany` is to `berlin` as `uk` is to _blank_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "_u99fXdhPzRF"
   },
   "outputs": [],
   "source": [
    "# we will first create the nearest neighbor model\n",
    "nbrs_glove = NearestNeighbors(n_neighbors = 5, metric = 'cosine').fit(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "0YSx1cpsQa2P"
   },
   "outputs": [],
   "source": [
    "# let's check if it works\n",
    "embedding_man = embedding_matrix[word_index['man']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "vlamFoD3QThr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['man', 'woman', 'boy', 'one', 'person']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# closest words to `man`\n",
    "dist, idx = nbrs_glove.kneighbors([embedding_man])\n",
    "[index_word[i] for i in idx[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "xWGeWlZjQpd9"
   },
   "outputs": [],
   "source": [
    "# now define the proper embedding to solve the analogy\n",
    "germany_embedding = embedding_matrix[word_index['germany']]\n",
    "berlin_embedding = embedding_matrix[word_index['berlin']]\n",
    "uk_embedding = embedding_matrix[word_index['uk']]\n",
    "blank_embedding = berlin_embedding - germany_embedding + uk_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "aCoYOiNPRif1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['uk', 'london', 'theatre', '2013', '2011']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the closest to blank_embedding\n",
    "# closest words to `man`\n",
    "dist, idx = nbrs_glove.kneighbors([blank_embedding])\n",
    "[index_word[i] for i in idx[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s6Py0Xc3SFln"
   },
   "source": [
    "### Q5: Biases\n",
    "\n",
    "As we discussed in class, there might be several biases in word embeddings. Use the list of occupations below and for each of them find whether `man` or `woman` is closest to it. In particular, first list all occupations that are closer to `man` than `woman`, and then all occupations that are closer to `woman` than `man`.\n",
    "\n",
    "_Hint_: Use the `cosine` distance between pairs of embeddings from the `SciPy` package. If the ocupation does not exist in the embedding matrix, skip it. Also, remember that the cosine distance is smaller when the embeddings are more similar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "Gr4lsaweTPG1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine([1,1], [1,1]):  0\n",
      "cosine([1,1], [0,1]):  0.29289321881345254\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "print('cosine([1,1], [1,1]): ', cosine([1,1], [1,1]))\n",
    "print('cosine([1,1], [0,1]): ', cosine([1,1], [0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "J1wk0iujRmyd"
   },
   "outputs": [],
   "source": [
    "occupation_list = \"\"\"technician, accountant, supervisor, engineer, worker, educator, clerk, counselor,\n",
    "inspector, mechanic, manager, therapist, administrator, salesperson, receptionist, librarian,\n",
    "advisor, pharmacist, janitor, psychologist, physician, carpenter, nurse, investigator,\n",
    "bartender, specialist, electrician, officer, pathologist, teacher, lawyer, planner, practitioner,\n",
    "plumber, instructor, surgeon, veterinarian, paramedic, examiner, chemist, machinist,\n",
    "appraiser, nutritionist, architect, hairdresser, baker, programmer, paralegal, hygienist,\n",
    "scientist\"\"\".replace('\\n', '').replace(' ', '').split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "LRIFdlWFSw_q"
   },
   "outputs": [],
   "source": [
    "man_embedding = embedding_matrix[word_index['man']]\n",
    "woman_embedding = embedding_matrix[word_index['woman']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "OEMLYEn4S_l3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occupations closer to 'man':\n",
      "['engineer', 'inspector', 'mechanic', 'manager', 'advisor', 'carpenter', 'investigator', 'officer', 'lawyer', 'planner', 'plumber', 'instructor', 'architect', 'scientist']\n",
      "\n",
      "Occupations closer to 'woman':\n",
      "['technician', 'supervisor', 'worker', 'educator', 'clerk', 'counselor', 'therapist', 'administrator', 'receptionist', 'librarian', 'pharmacist', 'janitor', 'psychologist', 'physician', 'nurse', 'bartender', 'teacher', 'practitioner', 'surgeon', 'veterinarian', 'paramedic', 'examiner', 'nutritionist', 'hairdresser', 'hygienist']\n"
     ]
    }
   ],
   "source": [
    "# Lists to hold occupations closer to 'man' and 'woman'\n",
    "closer_to_man = []\n",
    "closer_to_woman = []\n",
    "\n",
    "# Calculate distances and categorize occupations\n",
    "for occupation in occupation_list:\n",
    "    if occupation in word_index:\n",
    "        occupation_embedding = embedding_matrix[word_index[occupation]]\n",
    "        dist_to_man = cosine(occupation_embedding, man_embedding)\n",
    "        dist_to_woman = cosine(occupation_embedding, woman_embedding)\n",
    "        \n",
    "        if dist_to_man < dist_to_woman:\n",
    "            closer_to_man.append(occupation)\n",
    "        else:\n",
    "            closer_to_woman.append(occupation)\n",
    "\n",
    "# Print the results\n",
    "print(\"Occupations closer to 'man':\")\n",
    "print(closer_to_man)\n",
    "print(\"\\nOccupations closer to 'woman':\")\n",
    "print(closer_to_woman)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NK72utxcUnVd"
   },
   "source": [
    "Do you see a pattern in the results? Do you think there are biases?\n",
    "\n",
    "It seems like the men have a lot of technical or managerial jobs like engineer, carpenter, architect, and scientist while the women seems to have more nurturing or supportive roles like nurse, hairdresser, hygienist, clerk, educator.  There could be potential biases in historical roles as well as societal biases within the Glove embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nr26TxJncSI8"
   },
   "source": [
    "### Q6: Sequence to Sequence Embedding\n",
    "\n",
    "What is the problem with LSTM models, and why do we need **attention** to fix them? Give as an example of what happens with sequence to sequence models for translation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T8VFfCmAcdmh"
   },
   "source": [
    "LSTMs struggle with very long sequences, leading to loss of important information over time. The use of a single fixed-size context vector compresses the entire input sequence, which can be limiting for long and complex sequences. As the sequence length increases, important details may be lost. Additionally, LSTMs find it hard to align parts of the input sequence with the corresponding parts of the output sequence, which is crucial in tasks like translation. The attention mechanism addresses these issues by creating context vectors dynamically for each output step, focusing on different parts of the input sequence as needed. It preserves important information by concentrating on relevant parts of the input at each decoding step. The mechanism also learns which parts of the input sequence are relevant to each part of the output sequence, thus improving accuracy. Furthermore, attention weights can be visualized, showing which parts of the input the model focuses on for each output step, enhancing interpretability. In sequence-to-sequence models for translation, the standard seq2seq with LSTM without attention processes the input sequence to produce a single context vector during encoding. During decoding, it uses this fixed context vector, which may struggle to capture all nuances, especially for long sequences. With attention, the encoding phase produces a sequence of hidden states. The decoding phase generates a context vector for each output step by computing attention weights over the hidden states, dynamically focusing on different parts of the input. This allows the model to dynamically focus on different parts of the input sequence, leading to more accurate translations by effectively aligning input and output sequences."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "9GPBdovEzBmE",
    "r3JcopEi-R6f",
    "lOvzWswaN3_g",
    "6y6P_ep9P5r3",
    "s6Py0Xc3SFln",
    "nr26TxJncSI8"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
